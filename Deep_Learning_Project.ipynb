{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uuviq3qQkUFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be532017-42e3-409e-c146-4dedfcde5b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'encoder4editing'...\n",
            "remote: Enumerating objects: 172, done.\u001b[K\n",
            "remote: Counting objects: 100% (172/172), done.\u001b[K\n",
            "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
            "remote: Total 172 (delta 58), reused 136 (delta 52), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (172/172), 33.43 MiB | 21.28 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "--2024-04-30 16:49:10--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240430%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240430T164911Z&X-Amz-Expires=300&X-Amz-Signature=f2b72606047e36ee494500270d3d6855d38141c69596e6942fbd631938da98f0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-30 16:49:11--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240430%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240430T164911Z&X-Amz-Expires=300&X-Amz-Signature=f2b72606047e36ee494500270d3d6855d38141c69596e6942fbd631938da98f0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77854 (76K) [application/octet-stream]\n",
            "Saving to: ‘ninja-linux.zip’\n",
            "\n",
            "ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-04-30 16:49:11 (9.05 MB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n",
            "\n",
            "Archive:  ninja-linux.zip\n",
            "  inflating: /usr/local/bin/ninja    \n",
            "update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n"
          ]
        }
      ],
      "source": [
        "#@title Setup Repository\n",
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'encoder4editing'\n",
        "\n",
        "!git clone https://github.com/omertov/encoder4editing.git $CODE_DIR\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "\n",
        "from argparse import Namespace\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from utils.common import tensor2im\n",
        "from models.psp import pSp  # we use the pSp framework to load the e4e encoder.\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kQVvi3iaqP1",
        "outputId": "458d1f1d-f94f-4ffd-9173-6cfd69bf3129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bk4q7UpkvUn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "a0c400a4-35b5-41b0-b272-827e861f6c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ebd29d9f652d>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdown --id $file_id -O $file_dst'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mdownloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_with_pydrive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mexperiment_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cars_encode'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#@title Download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-ebd29d9f652d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, use_pydrive)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_pydrive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-ebd29d9f652d>\u001b[0m in \u001b[0;36mauthenticate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mgauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CredentialType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth_ephem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       _message.blocking_request(\n\u001b[0m\u001b[1;32m    282\u001b[0m           \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m           \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'auth_user_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "#@title Setup files downloader\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "download_with_pydrive = True\n",
        "\n",
        "class Downloader(object):\n",
        "    def __init__(self, use_pydrive):\n",
        "        self.use_pydrive = use_pydrive\n",
        "        current_directory = os.getcwd()\n",
        "        self.save_dir = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"pretrained_models\")\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "        if self.use_pydrive:\n",
        "            self.authenticate()\n",
        "\n",
        "    def authenticate(self):\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        self.drive = GoogleDrive(gauth)\n",
        "\n",
        "    def download_file(self, file_id, file_name):\n",
        "        file_dst = f'{self.save_dir}/{file_name}'\n",
        "        if os.path.exists(file_dst):\n",
        "            print(f'{file_name} already exists!')\n",
        "            return\n",
        "        if self.use_pydrive:\n",
        "            downloaded = self.drive.CreateFile({'id':file_id})\n",
        "            downloaded.FetchMetadata(fetch_all=True)\n",
        "            downloaded.GetContentFile(file_dst)\n",
        "        else:\n",
        "            !gdown --id $file_id -O $file_dst\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = MODEL_PATHS[experiment_type]\n",
        "downloader.download_file(file_id=path[\"id\"], file_name=path[\"name\"])"
      ],
      "metadata": {
        "id": "1XdSH5Z07Csz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRjtz6uLkTJs"
      },
      "source": [
        "## Step 1: Select Experiment Type\n",
        "Select which experiment you wish to perform inference on:\n",
        "1. ffhq_encode\n",
        "2. cars_encode\n",
        "3. horse_encode\n",
        "4. church_encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XESWAO65kTJt"
      },
      "outputs": [],
      "source": [
        "experiment_type = 'cars_encode'\n",
        "#@title Download\n",
        "MODEL_PATHS = {\n",
        "    \"ffhq_encode\": {\"id\": \"1cUv_reLE6k3604or78EranS7XzuVMWeO\", \"name\": \"e4e_ffhq_encode.pt\"},\n",
        "    \"cars_encode\": {\"id\": \"17faPqBce2m1AQeLCLHUVXaDfxMRU2QcV\", \"name\": \"e4e_cars_encode.pt\"},\n",
        "    \"horse_encode\": {\"id\": \"1TkLLnuX86B_BMo2ocYD0kX9kWh53rUVX\", \"name\": \"e4e_horse_encode.pt\"},\n",
        "    \"church_encode\": {\"id\": \"1-L0ZdnQLwtdy6-A_Ccgq5uNJGTqE7qBa\", \"name\": \"e4e_church_encode.pt\"}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4etDz82xkTJz"
      },
      "source": [
        "## Step 2: Download Pretrained Models\n",
        "As part of this repository, we provide pretrained models for each of the above experiments. We'll download the model for the selected experiments and save it to the folder `pretrained_models`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSnjlBZOkTJ0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tozsg81kTKA"
      },
      "source": [
        "## Step 3: Define Inference Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIhyc7RqkTKB"
      },
      "source": [
        "Below we have a dictionary defining parameters such as the path to the pretrained model to use and the path to the image to perform inference on.  \n",
        "While we provide default values to run this script, feel free to change as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kE5y1-skTKC"
      },
      "outputs": [],
      "source": [
        "EXPERIMENT_DATA_ARGS = {\n",
        "    \"ffhq_encode\": {\n",
        "        \"model_path\": \"pretrained_models/e4e_ffhq_encode.pt\",\n",
        "        \"image_path\": \"notebooks/images/input_img.jpg\"\n",
        "    },\n",
        "    \"cars_encode\": {\n",
        "        \"model_path\": \"/content/drive/MyDrive/Rotation Data/Link_e4e_cars_encode.pt\", #\"pretrained_models/e4e_cars_encode.pt\",\n",
        "        \"image_path\": \"notebooks/images/car_img.png\"\n",
        "    },\n",
        "    \"horse_encode\": {\n",
        "        \"model_path\": \"pretrained_models/e4e_horse_encode.pt\",\n",
        "        \"image_path\": \"notebooks/images/horse_img.jpg\"\n",
        "    },\n",
        "    \"church_encode\": {\n",
        "        \"model_path\": \"pretrained_models/e4e_church_encode.pt\",\n",
        "        \"image_path\": \"notebooks/images/church_img.jpg\"\n",
        "    }\n",
        "\n",
        "}\n",
        "# Setup required image transformations\n",
        "EXPERIMENT_ARGS = EXPERIMENT_DATA_ARGS[experiment_type]\n",
        "if experiment_type == 'cars_encode':\n",
        "    EXPERIMENT_ARGS['transform'] = transforms.Compose([\n",
        "            transforms.Resize((192, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "    resize_dims = (256, 192)\n",
        "else:\n",
        "    EXPERIMENT_ARGS['transform'] = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "    resize_dims = (256, 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAWrUehTkTKJ"
      },
      "source": [
        "## Step 4: Load Pretrained Model\n",
        "We assume that you have downloaded all relevant models and placed them in the directory defined by the above dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t-AOhP1kTKJ",
        "outputId": "2556e2bc-9185-45f1-94f4-6c9b99699ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading e4e over the pSp framework from checkpoint: /content/drive/MyDrive/Rotation Data/Link_e4e_cars_encode.pt\n",
            "Model successfully loaded!\n"
          ]
        }
      ],
      "source": [
        "model_path = EXPERIMENT_ARGS['model_path']\n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "# pprint.pprint(opts)  # Display full options used\n",
        "# update the training options\n",
        "opts['checkpoint_path'] = model_path\n",
        "#opts['encoder_type'] = model_path\n",
        "opts= Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print('Model successfully loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(opts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp57AK_qeHer",
        "outputId": "9cb1fce3-35c9-4f43-be6b-63eb9b8150d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(exp_dir='', dataset_type='cars_encode', encoder_type='Encoder4Editing', batch_size=8, test_batch_size=4, workers=8, test_workers=4, learning_rate=0.0001, optim_name='ranger', train_decoder=False, start_from_latent_avg=True, lpips_lambda=0.8, id_lambda=0.5, l2_lambda=1.0, stylegan_weights='', stylegan_size=512, checkpoint_path='/content/drive/MyDrive/Rotation Data/Link_e4e_cars_encode.pt', max_steps=200000, image_interval=100, board_interval=50, val_interval=10000, save_interval=200000, w_discriminator_lambda=0.1, w_discriminator_lr=2e-05, r1=10, d_reg_every=16, use_w_pool=True, w_pool_size=50, sub_exp_dir=None, delta_norm=2, delta_norm_lambda=0.0002, keep_optimizer=False, resume_training_from_ckpt=None, update_param_list=None, device='cuda:0', progressive_steps=[0, 20000, 22000, 24000, 26000, 28000, 30000, 32000, 34000, 36000, 38000, 40000, 42000, 44000, 46000, 48000], progressive_start=20000, progressive_step_every=2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Embeddings"
      ],
      "metadata": {
        "id": "gDRPyKmnEbS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from utils import data_utils\n",
        "from torch.utils.data import DataLoader\n",
        "class InferenceDataset(Dataset):\n",
        "\n",
        "\tdef __init__(self, root, opts, transform=None, preprocess=None):\n",
        "\t\tself.paths = sorted(data_utils.make_dataset(root))\n",
        "\t\tself.transform = transform\n",
        "\t\tself.preprocess = preprocess\n",
        "\t\tself.opts = opts\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.paths)\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tfrom_path = self.paths[index]\n",
        "\t\tif self.preprocess is not None:\n",
        "\t\t\tfrom_im = self.preprocess(from_path)\n",
        "\t\telse:\n",
        "\t\t\tfrom_im = Image.open(from_path).convert('RGB')\n",
        "\t\tif self.transform:\n",
        "\t\t\tfrom_im = self.transform(from_im)\n",
        "\t\treturn from_im"
      ],
      "metadata": {
        "id": "mrKJ5LKVJfq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from configs import data_configs\n",
        "\n",
        "@torch.no_grad()\n",
        "def setup_data_loader(opts ,img_path):\n",
        "    dataset_args = data_configs.DATASETS[opts.dataset_type]\n",
        "    transforms_dict = dataset_args['transforms'](opts).get_transforms()\n",
        "    images_path = img_path if img_path is not None else print('error in path')\n",
        "    print(f\"images path: {images_path}\")\n",
        "    align_function = None\n",
        "\n",
        "    test_dataset = InferenceDataset(root=images_path,\n",
        "                                    transform= EXPERIMENT_ARGS['transform'], #transforms_dict['transform_test'],\n",
        "                                    preprocess=align_function,\n",
        "                                    opts=opts)\n",
        "\n",
        "    data_loader = DataLoader(test_dataset,\n",
        "                             batch_size=1, #args.batch = 1\n",
        "                             shuffle=False,\n",
        "                             num_workers=2,\n",
        "                             drop_last=True)\n",
        "    print(f'dataset length: {len(test_dataset)}')\n",
        "    return data_loader\n",
        "def get_latents(net, x, is_cars=True):\n",
        "\n",
        "    #codes = net.encoder(x)\n",
        "    #codes = net(transformed_image.unsqueeze(0).to(\"cuda\").float(), randomize_noise=False, return_latents=True)[1]\n",
        "    codes = net(x, randomize_noise=False, return_latents=True)[1]\n",
        "    if codes.shape[1] == 18 and is_cars:\n",
        "        codes = codes[:, :16, :]\n",
        "    return codes\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_all_latents(net, data_loader, n_images=None, is_cars=True):\n",
        "    device='cuda'\n",
        "    all_latents = []\n",
        "    i = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            if n_images is not None and i > n_images:\n",
        "                break\n",
        "            x = batch\n",
        "            inputs = x.to(device).float()\n",
        "            latents = get_latents(net, inputs, is_cars)\n",
        "            all_latents.append(latents)\n",
        "            i += len(latents)\n",
        "    return torch.cat(all_latents)\n",
        "def save_image(img, save_dir, idx):\n",
        "    #result = tensor2im(img)\n",
        "    result = img\n",
        "    im_save_path = os.path.join(save_dir, f\"{idx:05d}.jpg\")\n",
        "    Image.fromarray(np.array(result)).save(im_save_path)\n",
        "@torch.no_grad()\n",
        "def decode_image(latent):\n",
        "  with torch.no_grad():\n",
        "    img1 = net.decoder([latent.unsqueeze(0)],input_is_latent=True, randomize_noise=False, return_latents=False)\n",
        "    img = img1[0][0]\n",
        "  return tensor2im(img)"
      ],
      "metadata": {
        "id": "HXalUWpPGr-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = setup_data_loader(opts ,img_path = '//content/drive/MyDrive/Rotation Data/BMW Cardekho 360/Cropped/birme-1000x500')\n",
        "# Get latent codes for all images\n",
        "latent_codes = get_all_latents(net, data_loader, n_images=None, is_cars=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFW6HS1rG2Y7",
        "outputId": "78fec2f2-3741-4f69-c204-1b7639b8ab43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images path: //content/drive/MyDrive/Rotation Data/BMW Cardekho 360/Cropped/birme-1000x500\n",
            "dataset length: 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(latent_codes))\n",
        "print(type(latent_codes))\n",
        "print(len(latent_codes[0]))\n",
        "print(type(latent_codes[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXPqNGeKY7_q",
        "outputId": "5afac33a-b245-4cfb-e5b8-2427c553668e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140\n",
            "<class 'torch.Tensor'>\n",
            "16\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(latent_codes[0].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_kbbMzKDHJR",
        "outputId": "7dd16f1e-b6fe-4cd8-a8ab-a61233bd2f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decode_image\n",
        "def save_inversions(latent_list , output_path , label):\n",
        "    inversions_directory_path = os.path.join(output_path, label)\n",
        "    os.makedirs(inversions_directory_path, exist_ok=True)\n",
        "    i = 1\n",
        "    for latent in latent_list:\n",
        "      img = decode_image(latent)\n",
        "      save_image(img,inversions_directory_path ,i )\n",
        "      i = i + 1"
      ],
      "metadata": {
        "id": "vxqKr2MZyE69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "def interpolate_list(original_list, ratio, kind='linear'):\n",
        "  \"\"\"\n",
        "  Interpolates a list of torch tensors.\n",
        "\n",
        "  Args:\n",
        "    original_list: The original list of torch tensors.\n",
        "    ratio: The ratio of elements to keep.\n",
        "    kind: The interpolation method ('linear', 'cubic', etc.).\n",
        "\n",
        "  Returns:\n",
        "    A new list of interpolated torch tensors with the same length as the original list.\n",
        "  \"\"\"\n",
        "  n = len(original_list)\n",
        "  num_elements = int(n * ratio)\n",
        "\n",
        "  # Include first and last indices for interpolation\n",
        "  indices = np.linspace(0, n-1, num_elements, dtype=int)\n",
        "  selected_elements = [original_list[i] for i in indices]\n",
        "\n",
        "  # Create interpolation function\n",
        "  x = indices  # Use the actual indices as x\n",
        "  y = torch.stack(selected_elements)\n",
        "  interp_func = interp1d(x, y, kind=kind, axis=0)\n",
        "\n",
        "  # Interpolate for the full range\n",
        "  new_x = np.arange(n)  # Indices for the full list\n",
        "  interpolated_tensors = interp_func(new_x)\n",
        "\n",
        "  # Create new list with interpolated tensors\n",
        "  new_list = interpolated_tensors.tolist()\n",
        "  return new_list\n",
        "\n",
        "# Example usage\n",
        "original_list = [torch.randn(16) for _ in range(140)]  # Replace with your actual list\n",
        "ratio = 0.1\n",
        "\n",
        "linear_list = interpolate_list(original_list, ratio, kind='linear')"
      ],
      "metadata": {
        "id": "pioeU5uz9hae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save_inversions(latent_list , output_path , label):\n",
        "output_path = \"/content/drive/MyDrive/Rotation Data/Interpolated_Inversions\"\n",
        "for i in range(1,10):\n",
        "  ratio = i/10\n",
        "  linear_list = interpolate_list(latent_codes.cpu(), ratio, kind='linear')\n",
        "  linear_list_gpu = torch.Tensor(linear_list)\n",
        "  #cubic_list = interpolate_list(latent_codes, ratio, kind='cubic')\n",
        "  save_inversions(linear_list_gpu.to(\"cuda\") ,output_path , f\"Image_Ratio_{ratio}_linear\")\n",
        "  #save_inversions(cubic_list ,output_path , f\"Image_Ratio_{ratio}_cubic\")"
      ],
      "metadata": {
        "id": "uAinsm8g_5b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Calculate L2 norms\n",
        "original_norms = [torch.linalg.norm(t).item() for t in original_list]\n",
        "linear_norms = [torch.linalg.norm(torch.tensor(t)).item() for t in linear_list]  # Convert to tensor\n",
        "cubic_norms = [torch.linalg.norm(torch.tensor(t)).item() for t in cubic_list]  # Convert to tensor\n",
        "\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(original_norms, label='Original')\n",
        "plt.plot(linear_norms, label='Linear')\n",
        "plt.plot(cubic_norms, label='Cubic')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('L2 Norm')\n",
        "plt.title('L2 Norms of Tensors - Interpolation Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4E2VQ35f_RvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_inversions(latent_codes , \"/content/drive/MyDrive/Rotation Data/Simple_inversion\",\"all_labels\" )"
      ],
      "metadata": {
        "id": "PDlR3pFDy0Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ulydu9Ej0znw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/file.zip \"/content/Test Points/inversions\"\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "metadata": {
        "id": "FLqJsY2vLVoX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}